<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
    <title>
      Python Jieba库 | Niko&#39;s Blog | 世间所有的相遇，都是久别重逢</title>

  
  <meta name="author" content="Niko">
  

  
  <meta name="description" content="介绍Jieba扩展库">
  

  
  <meta name="keywords" content="Niko,NikoBlog,教程,小学生,筱晓,学习分享,csdn,博客园">
  

  <meta id="viewport" name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">

  <meta property="og:title" content="Python Jieba库"/>

  <meta property="og:site_name" content="Niko&#39;s Blog"/>

  
  <meta property="og:image" content="cover.webp" />
  
  
  <link rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css">
  <script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"></script>
  <script src="//lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js"> </script>
  <link href="/favicon.ico" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Niko&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <script type="text/javascript">
    (function (c, l, a, r, i, t, y) {
      c[a] = c[a] || function () { (c[a].q = c[a].q || []).push(arguments) };
      t = l.createElement(r); t.async = 1; t.src = "https://www.clarity.ms/tag/" + i;
      y = l.getElementsByTagName(r)[0]; y.parentNode.insertBefore(t, y);
    })(window, document, "clarity", "script", "ag8ctuxw9k");
  </script>
  <style>
  body {
    font-family: ' harmony'; } </style>

        
<script src="/js/fancybox.js"></script>

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div class="blog">
  <div class="content">

    <header>
  <div class="site-branding">
    <h1 class="site-title">
      <a href="/">Niko&#39;s Blog</a>
    </h1>
    <p class="site-description">世间所有的相遇，都是久别重逢</p>
  </div>
  <nav class="site-navigation">
    <ul>
      
        <li><a href="/">主页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
        <li><a href="/categories">分类</a></li>
      
        <li><a href="/tags">标签</a></li>
      
        <li><a href="/about">关于</a></li>
      
    </ul>
  </nav>
</header>

    <main class="site-main posts-loop">
    <article>

  
    
    <h3 class="article-title"><span>Python Jieba库</span></h3>
    
  

  <div class="article-top-meta">
    <span class="posted-on">
      <a href="/article/2176063644/" rel="bookmark">
        <time class="entry-date published" datetime="2022-01-06T05:11:13.000Z">
          2022-01-06
        </time>
      </a>
    </span>
  </div>


  

  <div class="article-content">
    <div class="entry">
      
        <h2 id="1-jieba-的江湖地位"><a href="#1-jieba-的江湖地位" class="headerlink" title="1. jieba 的江湖地位"></a><strong>1. jieba 的江湖地位</strong></h2><p>NLP（自然语言）领域现在可谓是群雄纷争，各种开源组件层出不穷，其中一支不可忽视的力量便是 jieba 分词，号称要做最好的 Python 中文分词组件。</p>
<span id="more"></span>
<p><img loading="lazy" src="https://pic1.zhimg.com/v2-144f02ac2b50ee5841fb2bee3fa36948_r.jpg"></p>
<p>“最好的” 这三个字可不是空穴来风，jieba 在开源社区的受欢迎程度非常之高。</p>
<p>jieba 项目目前的 github star 数已经达到 24k，其他热门分词组件像 HanLP star 数 20k、ansj_seg star 数 5.6k、pkuseg-python star 数 5k。可见 jieba 已经稳居中文分词领域 c 位。</p>
<p><img loading="lazy" src="https://pic4.zhimg.com/v2-a46b69b27e9cdd27460ef7521de90de7_r.jpg"></p>
<p>jieba 的主要功能是做中文分词，可以进行简单分词、并行分词、命令行分词，当然它的功能不限于此，目前还支持关键词提取、词性标注、词位置查询等。</p>
<p>更让人愉悦的是 jieba 虽然立足于 python，但同样支持其他语言和平台，诸如：C++、Go、R、Rust、Node.js、PHP、 iOS、Android 等。所以 jieba 能满足各类开发者的需求。</p>
<h2 id="2-如何学-jieba"><a href="#2-如何学-jieba" class="headerlink" title="2. 如何学 jieba"></a><strong>2. 如何学 jieba</strong></h2><p>据我所知，jieba 最靠谱的文档是 github 项目的 readme，因为它似乎还没有独立的使用文档。但由于使用起来简单，看 readme 也能快速上手。</p>
<p><em><a target="_blank" rel="noopener external nofollow noopener noreferrer" href="https://github.com/fxsjy/jieba" target="_blank">Jieba库的Github地址</a></em></p>
<p>国内各大博客有关于 jieba 的使用教程，但需要甄别下准确度和时效性，因为 jieba 项目一直在更新。</p>
<p>当然本文不是纯粹的种草文章，会简单介绍下 jieba 的使用方法。</p>
<h2 id="3-安装-jieba"><a href="#3-安装-jieba" class="headerlink" title="3. 安装 jieba"></a><strong>3. 安装 jieba</strong></h2><p>jieba 支持<code>pip</code>或者<code>conda</code>安装，直接在命令行执行：</p>
<pre class="line-numbers language-none"><code class="language-none">pip install jieba<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>不出意外，应该能很快安装好。</p>
<p><img loading="lazy" src="https://pic2.zhimg.com/v2-154d371fe8a4e1dd06829913b88c04a9_r.jpg"></p>
<p>你也可以下载 jieba 安装包再安装，jieba 的 pypi 地址：</p>
<p><em><a target="_blank" rel="noopener external nofollow noopener noreferrer" href="http://pypi.python.org/pypi/jieba/" target="_blank">Pypi地址</a></em></p>
<h2 id="4-分词初体验"><a href="#4-分词初体验" class="headerlink" title="4. 分词初体验"></a><strong>4. 分词初体验</strong></h2><p>分词是 NLP 处理的第一步，也是最基本的任务，分词的好坏直接决定了后面语义分析的精准度。</p>
<p>所谓分词就是将一段表述里的词汇进行分解，比如 “我爱中国”，分解后有三个词：我、爱、中国，词性分别是名词、动词、名词。</p>
<p>jieba 库中用于分词的方法有三个：</p>
<h3 id="jieba-cut"><a href="#jieba-cut" class="headerlink" title="jieba.cut"></a><strong>jieba.cut</strong></h3><p>给定中文字符串，分解后返回一个迭代器，需要用 for 循环访问。</p>
<p>参数解释：  </p>
<p><strong>「strs」</strong>： 需要分词的字符串；<br><strong>「cut_all」</strong>：用来控制是否采用全模式；<br><strong>「HMM」</strong>：用来控制是否使用 HMM 模型；<br><strong>「use_paddle」</strong>：用来控制是否使用 paddle 模式下的分词模式，paddle 模式采用延迟加载方式，通过 enable_paddle 接口安装 paddlepaddle-tiny，并且 import 相关代码；  </p>
<p>这里区分全模式和精确模式，举个例子先看看区别：</p>
<pre class="line-numbers language-none"><code class="language-none"># 全模式
seg_list &#x3D; jieba.cut(&quot;中国上海是一座美丽的国际性大都市&quot;, cut_all&#x3D;True)
print(&quot;Full Mode: &quot; + &quot;&#x2F; &quot;.join(seg_list))  

# 返回结果
Full Mode: 中国&#x2F; 上海&#x2F; 是&#x2F; 一座&#x2F; 美丽&#x2F; 的&#x2F; 国际&#x2F; 国际性&#x2F; 大都&#x2F; 大都市&#x2F; 都市

# 精确模式
seg_list &#x3D; jieba.cut(&quot;中国上海是一座美丽的国际性大都市&quot;, cut_all&#x3D;False)
print(&quot;Full Mode: &quot; + &quot;&#x2F; &quot;.join(seg_list))  

# 返回结果
Default Mode: 中国&#x2F; 上海&#x2F; 是&#x2F; 一座&#x2F; 美丽&#x2F; 的&#x2F; 国际性&#x2F; 大都市<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>可以看到，全模式把句子中所有的可以成词的词语都扫描出来, 会出现一词多用、一词多意。精确模式将句子最精确的切分开，每个词都只有一种含义。</p>
<p><code>jieba.cut</code>方法默认是精确模式。</p>
<p>还有一个参数控制 paddle 模式，会更加精确，使用这个的前提是你需要先安装 paddlepaddle-tiny。  </p>
<p>安装命令：<br><code>pip install paddlepaddle-tiny==1.6.1</code></p>
<p>详情可以去官网看下，这里不举例。</p>
<h3 id="jieba-cut-for-search"><a href="#jieba-cut-for-search" class="headerlink" title="jieba.cut_for_search"></a><strong>jieba.cut_for_search</strong></h3><p>该方法和 cut 一样，分解后返回一个迭代器，需要用 for 循环访问。不过它是搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</p>
<p>参数解释：</p>
<p><strong>「strs」</strong>：需要分词的字符串；<br><strong>「HMM」</strong>：是否使用 HMM 模型，默认值为 True。该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细。  </p>
<pre class="line-numbers language-none"><code class="language-none"># 搜索引擎模式
seg_list &#x3D; jieba.cut_for_search(&quot;中国上海是一座美丽的国际性大都市，拥有复旦大学、上海交通大学等知名高等学府&quot;)  
print(&quot;, &quot;.join(seg_list))

# 返回结果
Search Mode: 中国, 上海, 是, 一座, 美丽, 的, 国际, 国际性, 大都, 都市, 大都市, ，, 拥有, 复旦, 大学, 复旦大学, 、, 上海, 交通, 大学, 上海交通大学, 等, 知名, 高等, 学府, 高等学府<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="jieba-lcut"><a href="#jieba-lcut" class="headerlink" title="jieba.lcut"></a><strong>jieba.lcut</strong></h3><p>和<code>jieba.cut</code>使用方法一样，不过返回的是列表。</p>
<p>cut 和 cut_for_search 方法都是支持繁体字的。</p>
<h2 id="5-添加自定义词典"><a href="#5-添加自定义词典" class="headerlink" title="5. 添加自定义词典"></a><strong>5. 添加自定义词典</strong></h2><p>如果是对专业新闻或者小说进行分词，会有很多的新词汇，jieba 库里没有就没办法识别，那么就需要添加自定义的词汇，比如：奥利给。</p>
<p>添加自定义词汇的方法： <code>jieba.load_userdict(file_name)</code> 参数是文本文件，txt、csv 都可以。</p>
<p>自定义词典文件的词汇格式是一个词占一行，每一行分三部分：词语、词频（可省略）、词性（可省略），用空格隔开，顺序不可颠倒。 比如：</p>
<p><img loading="lazy" src="https://pic3.zhimg.com/v2-006e9b57a6f284ddce4f14314b8caa7a_b.jpg"></p>
<p>以 “奥利给，管虎执导的八佰是一部让人热血沸腾的好电影。” 这段话为例， 如果不添加自定义词典，很多词没办法识别出来。</p>
<pre class="line-numbers language-none"><code class="language-none"># 不添加自定义词典
seg_list &#x3D; jieba.cut(&quot;奥利给，管虎执导的八佰是一部让人热血沸腾的好电影&quot;)
print(&quot;&#x2F; &quot;.join(seg_list))  

# 返回结果
奥利&#x2F; 给&#x2F; ，&#x2F; 管虎&#x2F; 执导&#x2F; 的&#x2F; 八佰是&#x2F; 一部&#x2F; 让&#x2F; 人&#x2F; 热血沸腾&#x2F; 的&#x2F; 好&#x2F; 电影<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>添加自定义词典后，新词、人名、电影名都可以识别出来</p>
<pre class="line-numbers language-none"><code class="language-none"># 载入词典
jieba.load_userdict(&quot;dict.txt&quot;)
seg_list &#x3D; jieba.cut(&quot;奥利给，管虎执导的八佰是一部让人热血沸腾的好电影&quot;)
print(&quot;&#x2F; &quot;.join(seg_list))  

# 返回结果
奥利给&#x2F; ，&#x2F; 管虎&#x2F; 执导&#x2F; 的&#x2F; 八佰&#x2F; 是&#x2F; 一部&#x2F; 让&#x2F; 人&#x2F; 热血沸腾&#x2F; 的&#x2F; 好&#x2F; 电影<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6. 结论"></a><strong>6. 结论</strong></h2><p>jieba 无疑是一款优秀的分词工具，而且在不断地优化成长。前面讲了一些基本的使用，大家还可以尝试使用停用词、提取关键词、词性标注、词位置查询等功能，也是十分的便捷。</p>

      
    </div>

  </div>

  <div class="article-footer">
    <div class="article-meta pull-left">

    
      

    <span class="post-categories">
      <i class="icon-categories"></i>
        <a href="/categories/🛫万年鲲鹏号/">🛫万年鲲鹏号</a>
    </span>
    

    
    

    <span class="post-tags">
      <i class="icon-tags"></i>
        <a href="/tags/🐍Python/">🐍Python</a>
    </span>
    

    </div>

    
  </div>
</article>

  









    </main>

    <footer class="site-footer">
  <p class="site-info">
    Proudly powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer" target="_blank">Hexo</a> and
    Theme by <a href="https://github.com/CodeDaraW/Hacker" target="_blank" rel="external nofollow noopener noreferrer" target="_blank">Hacker</a>
    </br>
    
    &copy; 2022 Niko
    
  </p>
</footer>
    
    
  </div>
</div>
<script>
    if(!('loading' in HTMLImageElement.prototype)) {
        const srp = document.createElement('script');
        srp.src = 'https://cdn.jsdelivr.net/npm/lazysizes@5.1.1/lazysizes.min.js';
        document.body.append(srp);
        const imgs = document.querySelectorAll('img');
        imgs.forEach(el => {
            el.setAttribute('data-src', el.getAttribute('src'));
            el.removeAttribute('src');
            el.classList.add('lazyload');
    })
}
</script></body>
</html>